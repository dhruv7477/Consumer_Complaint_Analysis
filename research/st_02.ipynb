{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path: Path\n",
    "    file_path: Path\n",
    "    params_num_labels: int\n",
    "    params_test_size: float\n",
    "    params_learning_rate: float\n",
    "    params_random_state: int\n",
    "    params_batch_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Consumer_Complaint_Analysis.constants import *\n",
    "from Consumer_Complaint_Analysis.utils import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        config = self.config\n",
    "        params = self.params\n",
    "        create_directories([config.prepare_base_model.root_dir])\n",
    "\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(config.prepare_base_model.root_dir),\n",
    "            base_model_path=Path(config.prepare_base_model.base_model_path),\n",
    "            file_path=Path(config.data_ingestion.csv_file_path),\n",
    "            params_num_labels=params.NUM_LABELS,\n",
    "            params_test_size=params.TEST_SIZE,\n",
    "            params_learning_rate=params.LEARNING_RATE,\n",
    "            params_random_state=params.RANDOM_STATE,\n",
    "            params_batch_size=params.BATCH_SIZE\n",
    "        )\n",
    "\n",
    "        return prepare_base_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class DataPreProcessing:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def pre_process_data(self, path):\n",
    "        \"\"\"get pre processed data\n",
    "    \n",
    "        Args:\n",
    "            path (str or Path): path of the file\n",
    "    \n",
    "        Returns:\n",
    "            df: Pre Processed Data Frame\n",
    "        \"\"\"\n",
    "    \n",
    "        df = pd.read_csv(path)\n",
    "    \n",
    "        # Pre-processing\n",
    "        # Replacing the NaN values with the most frequent value in each column\n",
    "        for column in df.columns:\n",
    "            df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "\n",
    "        # Convert the target column to 0 or 1\n",
    "        df['Consumer disputed?'] = df['Consumer disputed?'].map({'No': 0, 'Yes': 1})\n",
    "        df['Consumer disputed?'] = df['Consumer disputed?'].astype(int)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Coding_Notes\\Consumer_Complaint_Analysis\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "class PrepareBaseModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def analyze_firm_size_market_share(self, df):\n",
    "        firm_size = df.groupby(['Company'])['Consumer complaint narrative'].count().reset_index(name='Complaint Count')\n",
    "        firm_size['Market Share'] = firm_size['Complaint Count'] / firm_size['Complaint Count'].sum()\n",
    "        return firm_size\n",
    "    \n",
    "    def analyze_population_of_state(self, df):\n",
    "        state_population = df.groupby(['State'])['Consumer complaint narrative'].count().reset_index()\n",
    "        state_population = state_population.rename(columns={'Consumer complaint narrative': 'Complaint Count'})\n",
    "        state_population['Complaint per Capita'] = state_population['Complaint Count'] / df['State'].value_counts()\n",
    "        self.state_population = state_population\n",
    "        return state_population\n",
    "        \n",
    "    def analyze_population_of_ZIP_code(self, df):\n",
    "        ZIP_code_population = df.groupby(['ZIP code'])['Consumer complaint narrative'].count().reset_index()\n",
    "        ZIP_code_population = ZIP_code_population.rename(columns={'Consumer complaint narrative': 'Complaint Count'})\n",
    "        ZIP_code_population['Complaint per Capita'] = ZIP_code_population['Complaint Count'] / df['ZIP code'].value_counts()\n",
    "        self.ZIP_code_population = ZIP_code_population\n",
    "        return ZIP_code_population\n",
    "\n",
    "    def truncate_sequence(self,sequence, max_length=512):\n",
    "        if len(sequence) > max_length:\n",
    "            sequence = sequence[:max_length]\n",
    "        return sequence\n",
    "        \n",
    "    def get_base_model(self, df):\n",
    "        df = df.head(1000)\n",
    "        #df = df.sample(frac=0.5)\n",
    "\n",
    "        # Tokenization\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        sequences = df['Consumer complaint narrative'].tolist()\n",
    "        truncated_sequences = [self.truncate_sequence(seq, max_length=512) for seq in sequences]\n",
    "        encoded_data = tokenizer.batch_encode_plus(truncated_sequences, pad_to_max_length=True, return_attention_mask=True)\n",
    "        input_ids = torch.tensor(encoded_data['input_ids'])\n",
    "        attention_mask = torch.tensor(encoded_data['attention_mask'])\n",
    "        labels = torch.tensor(df['Consumer disputed?'].tolist())\n",
    "        train_inputs, test_inputs, train_labels, test_labels = train_test_split(input_ids, labels, test_size=self.config.params_test_size, random_state=self.config.params_random_state)\n",
    "        train_masks, test_masks, _, _ = train_test_split(attention_mask, input_ids, test_size=self.config.params_test_size, random_state=self.config.params_random_state)\n",
    "\n",
    "        # Analyze firm size and market share\n",
    "        self.analyze_firm_size_market_share(df)\n",
    "        \n",
    "        # Analyze population of a state\n",
    "        self.analyze_population_of_state(df)\n",
    "        \n",
    "        # Analyze population of a ZIP code\n",
    "        self.analyze_population_of_ZIP_code(df)\n",
    "\n",
    "        # Creating a TensorDataset\n",
    "        train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "        test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "\n",
    "        # Data Loaders\n",
    "        train_dataloader = DataLoader(train_data, batch_size=self.config.params_batch_size, shuffle=True)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=self.config.params_batch_size, shuffle=False)\n",
    "\n",
    "        self.dataloaders = {\"train\": train_dataloader, \"val\": test_dataloader}\n",
    "        \n",
    "        # Model Configuration\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=self.config.params_num_labels)\n",
    "        self.model = model\n",
    "        self.save_model(self.config.base_model_path, self.model)\n",
    "        \n",
    "    @staticmethod\n",
    "    def save_model(path, model):\n",
    "        torch.save(model.state_dict(),path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovol\\AppData\\Local\\Temp\\ipykernel_10344\\4190997387.py:18: DtypeWarning: Columns (9,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n",
      "f:\\Coding_Notes\\Consumer_Complaint_Analysis\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_base_model_config = config.get_prepare_base_model_config()\n",
    "    Data = DataPreProcessing(config=prepare_base_model_config)\n",
    "    df = Data.pre_process_data(prepare_base_model_config.file_path)\n",
    "    prepare_base_model = PrepareBaseModel(config=prepare_base_model_config)\n",
    "    prepare_base_model.get_base_model(df)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0933eedb68cbe398ff033e891e3deb75331952e6373c8260509fd558998e38d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
